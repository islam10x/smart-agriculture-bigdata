# ğŸŒ¾ Smart Agriculture Big Data Platform

A comprehensive big data platform for smart agriculture that integrates IoT sensor data, disease detection using computer vision, and real-time analytics for precision farming.

## ğŸ“‹ Overview

This platform leverages modern big data technologies to provide farmers and agricultural organizations with actionable insights from IoT sensors, weather data, and plant disease detection. The system is built using a microservices architecture with distributed data processing capabilities.

### Key Features

- **ğŸ“Š Real-time IoT Data Processing**: Collect and process sensor data from agricultural fields (temperature, humidity, soil moisture, etc.)
- **ğŸ”¬ Plant Disease Detection**: Computer vision-based disease detection using machine learning models
- **â˜ï¸ Weather Integration**: Real-time weather data integration for predictive analytics
- **ğŸ“ˆ Advanced Analytics**: Spark-based batch processing for historical data analysis
- **ğŸ¯ Intelligent Alerts**: Automated alerting system for critical farming conditions
- **ğŸ“Š Interactive Dashboards**: React-based web dashboard with real-time visualizations
- **ğŸ—„ï¸ Distributed Storage**: HDFS-based distributed file system for large-scale data storage

## ğŸ—ï¸ Architecture

The platform uses a modern microservices architecture with the following components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     React Dashboard (Port 3000)              â”‚
â”‚                   + Grafana Analytics (Port 3001)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Backend (Port 8000)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                            â”‚
           â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB (NoSQL)    â”‚    â”‚   PostgreSQL (Metadata)      â”‚
â”‚   - Sensor Data      â”‚    â”‚   - Fields & Sensors         â”‚
â”‚   - Disease Records  â”‚    â”‚   - Batch Jobs               â”‚
â”‚   - Weather Data     â”‚    â”‚   - Analytics Summary        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Apache Spark Cluster (Batch Processing)         â”‚
â”‚         Master (8080) + 3 Workers (Spark 3.5.0)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Hadoop HDFS Cluster (Distributed Storage)         â”‚
â”‚     NameNode (9870) + 3 DataNodes (Hadoop 3.2.1)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Data Gateway Service (IoT Ingestion) (5001)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Optional: Kafka + Zookeeper (Streaming)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technology Stack

### Backend
- **FastAPI**: High-performance REST API framework
- **Python 3.11**: Core programming language
- **Motor**: Async MongoDB driver

### Big Data Processing
- **Apache Spark 3.5.0**: Distributed data processing
- **Apache Hadoop 3.2.1**: Distributed file system (HDFS)
- **PySpark**: Python interface for Spark

### Databases
- **MongoDB 7.0**: NoSQL database for sensor data and time-series
- **PostgreSQL 16**: Relational database for metadata and analytics

### Frontend
- **React 18.2**: Modern web framework
- **Grafana 10.2**: Data visualization and monitoring

### Machine Learning
- **scikit-learn**: Machine learning models
- **OpenCV**: Computer vision for disease detection
- **Pillow**: Image processing

### Optional Streaming
- **Apache Kafka 7.5**: Real-time data streaming
- **Zookeeper**: Kafka cluster coordination

### DevOps
- **Docker & Docker Compose**: Containerization and orchestration
- **Nginx**: Web server for frontend

## ğŸ“¦ Project Structure

```
smart-agriculture-bigdata/
â”œâ”€â”€ api/                    # FastAPI backend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ models/        # Pydantic data models
â”‚   â”‚   â””â”€â”€ database/      # Database connections
â”‚   â”œâ”€â”€ tests/             # API tests
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dashboard/             # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â””â”€â”€ services/      # API service clients
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ gateway/               # Data ingestion gateway
â”‚   â”œâ”€â”€ src/              # Gateway service code
â”‚   â”œâ”€â”€ config/           # Configuration files
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ spark/                 # Spark processing jobs
â”‚   â”œâ”€â”€ batch_jobs/       # Batch processing scripts
â”‚   â”œâ”€â”€ ml_models/        # ML model training
â”‚   â”œâ”€â”€ computer_vision/  # Disease detection models
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ raw/              # Raw data files
â”‚   â”œâ”€â”€ processed/        # Processed datasets
â”‚   â”œâ”€â”€ models/           # Trained ML models
â”‚   â”œâ”€â”€ staging/          # Staging area
â”‚   â””â”€â”€ hdfs/             # HDFS mount point
â”‚
â”œâ”€â”€ hadoop/                # Hadoop configuration
â”‚   â”œâ”€â”€ hadoop-config/
â”‚   â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ hadoop.env
â”‚
â”œâ”€â”€ mongodb/               # MongoDB initialization
â”‚   â”œâ”€â”€ init-scripts/     # Database init scripts
â”‚   â””â”€â”€ schemas/          # Collection schemas
â”‚
â”œâ”€â”€ postgres/              # PostgreSQL initialization
â”‚   â””â”€â”€ init-scripts/     # SQL init scripts
â”‚
â”œâ”€â”€ grafana/               # Grafana dashboards
â”‚   â”œâ”€â”€ dashboards/       # Dashboard JSON files
â”‚   â””â”€â”€ datasources/      # Datasource configs
â”‚
â”œâ”€â”€ scripts/               # Utility scripts
â”‚   â””â”€â”€ health-check.sh   # Service health check
â”‚
â”œâ”€â”€ logs/                  # Application logs
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ docker-compose.yml     # Docker orchestration
â”œâ”€â”€ setup.sh              # Full setup script
â”œâ”€â”€ quick-setup.sh        # Quick setup script
â”œâ”€â”€ .env                  # Environment variables
â””â”€â”€ README.md             # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **Minimum 8GB RAM**
- **Minimum 30GB free disk space**

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/islam10x/smart-agriculture-bigdata.git
   cd smart-agriculture-bigdata
   ```

2. **Run the automated setup script**
   ```bash
   chmod +x setup.sh
   ./setup.sh
   ```

   The setup script will:
   - Check system requirements
   - Create necessary directory structure
   - Generate environment files
   - Create Dockerfiles and init scripts
   - Start all Docker services

3. **Configure environment variables**
   ```bash
   # Edit .env file and add your API keys
   nano .env
   # Add your OpenWeatherMap API key
   WEATHER_API_KEY=your_api_key_here
   ```

### Manual Setup

If you prefer manual setup:

```bash
# 1. Create environment file
cp .env.example .env

# 2. Build and start services
docker-compose build
docker-compose up -d

# 3. Verify services are running
docker-compose ps
```

### Quick Setup (Existing Configuration)

```bash
chmod +x quick-setup.sh
./quick-setup.sh
```

## ğŸŒ Service Access

Once all services are running, access them at:

| Service | URL | Credentials |
|---------|-----|-------------|
| ğŸ“Š **React Dashboard** | http://localhost:3000 | - |
| ğŸ”§ **FastAPI Docs** | http://localhost:8000/docs | - |
| âš¡ **Spark Master UI** | http://localhost:8080 | - |
| ğŸ“‚ **Hadoop NameNode** | http://localhost:9870 | - |
| ğŸ—ƒï¸ **MongoDB Express** | http://localhost:8081 | admin / admin123 |
| ğŸ“ˆ **Grafana** | http://localhost:3001 | admin / admin123 |
| ğŸ‘· **Spark Worker 1** | http://localhost:8082 | - |
| ğŸ‘· **Spark Worker 2** | http://localhost:8083 | - |
| ğŸ‘· **Spark Worker 3** | http://localhost:8084 | - |

### Database Access

**MongoDB**
```bash
# Connect to MongoDB
docker-compose exec mongodb mongosh -u admin -p admin123
```

**PostgreSQL**
```bash
# Connect to PostgreSQL
docker-compose exec postgres psql -U postgres -d agriculture_meta
```

## ğŸ“Š Usage Examples

### 1. Start IoT Sensor Simulator

```bash
docker-compose exec gateway python src/sensor_simulator.py
```

### 2. Run Spark Batch Jobs

```bash
# Run disease analytics job
docker-compose exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/disease_analytics.py

# Run data aggregation job
docker-compose exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/data_aggregation.py
```

### 3. Upload Data to HDFS

```bash
# Copy data to HDFS
docker-compose exec namenode hdfs dfs -put /data/sensor_data.csv /agriculture/
```

### 4. View Logs

```bash
# View all logs
docker-compose logs -f

# View specific service logs
docker-compose logs -f api
docker-compose logs -f spark-master
```

### 5. Health Check

```bash
chmod +x scripts/health-check.sh
./scripts/health-check.sh
```

## ğŸ”§ Configuration

### Environment Variables

Key environment variables in `.env`:

```bash
# API Keys
WEATHER_API_KEY=your_openweathermap_api_key

# MongoDB
MONGODB_URI=mongodb://admin:admin123@mongodb:27017/
MONGO_INITDB_DATABASE=agriculture

# PostgreSQL
POSTGRES_DB=agriculture_meta
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres123

# Spark
SPARK_MASTER_URL=spark://spark-master:7077

# API
API_HOST=0.0.0.0
API_PORT=8000

# Dashboard
REACT_APP_API_URL=http://localhost:8000
```

### Scaling Workers

To add more Spark workers, edit `docker-compose.yml` and add additional worker services.

## ğŸ§ª Testing

### API Tests

```bash
# Run API tests
docker-compose exec api pytest src/tests/
```

### Service Health Check

```bash
./scripts/health-check.sh
```

## ğŸ“š API Documentation

Once the API service is running, access interactive API documentation at:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ¯ Key Workflows

### 1. Sensor Data Pipeline

```
IoT Sensors â†’ Gateway Service â†’ MongoDB â†’ Spark Processing â†’ Analytics
```

### 2. Disease Detection Pipeline

```
Image Upload â†’ Computer Vision Model â†’ Disease Classification â†’ Alert Generation
```

### 3. Weather Analytics Pipeline

```
Weather API â†’ Gateway â†’ MongoDB â†’ Spark Aggregation â†’ Dashboard Visualization
```

## ğŸ›‘ Stopping Services

```bash
# Stop all services
docker-compose down

# Stop and remove all data (âš ï¸ WARNING: This deletes all data)
docker-compose down -v

# Stop specific service
docker-compose stop <service-name>
```

## ğŸ” Monitoring

### View Resource Usage

```bash
# Docker stats
docker stats

# View Spark cluster status
# Open http://localhost:8080

# View Hadoop cluster status
# Open http://localhost:9870
```

### Grafana Dashboards

1. Navigate to http://localhost:3001
2. Login with `admin` / `admin123`
3. Explore pre-configured dashboards for:
   - Sensor data trends
   - Disease detection statistics
   - Weather patterns
   - System health metrics

## ğŸ› Troubleshooting

### Service won't start

```bash
# Check logs
docker-compose logs <service-name>

# Restart specific service
docker-compose restart <service-name>

# Rebuild service
docker-compose build <service-name>
docker-compose up -d <service-name>
```

### Network issues

```bash
# Recreate network
docker-compose down
docker network prune
docker-compose up -d
```

### Storage issues

```bash
# Check HDFS status
docker-compose exec namenode hdfs dfsadmin -report

# Check disk usage
docker system df
```

## ğŸ“ Learning Resources

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Hadoop Documentation](https://hadoop.apache.org/docs/stable/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [MongoDB Manual](https://docs.mongodb.com/)

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Support

For issues and questions, please create an issue in the repository.

## ğŸ¯ Future Enhancements

- [ ] Real-time streaming with Kafka integration
- [ ] Mobile application for farmers
- [ ] Advanced ML models for crop yield prediction
- [ ] Integration with drone imagery
- [ ] Multi-language support
- [ ] Enhanced security with OAuth2
- [ ] Automated backup and disaster recovery
- [ ] Support for additional IoT protocols (MQTT, CoAP)

## ğŸ“Š Project Status

This project is actively maintained and under continuous development. Check the [issues](../../issues) page for planned features and known bugs.

---

**Built with â¤ï¸ for sustainable agriculture and precision farming**
